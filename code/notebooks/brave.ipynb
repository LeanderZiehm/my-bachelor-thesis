{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eeb84de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# ─── CONFIG ─────────────────────────────────────────────────────────────────────\n",
    "API_KEY = os.getenv(\"BRAVE_SEARCH_API_KEY\")\n",
    "if not API_KEY:\n",
    "    raise ValueError(\"Please set BRAVE_SEARCH_API_KEY as an environment variable.\")\n",
    "\n",
    "QUERY = \"Predicting Customer Lifetime Value\"\n",
    "OUTPUT_CSV = \"clv_search_results.csv\"\n",
    "\n",
    "BASE_URL = \"https://api.search.brave.com/res/v1/web/search\"\n",
    "HEADERS = {\n",
    "    \"Accept\": \"application/json\",\n",
    "    \"Accept-Encoding\": \"gzip\",\n",
    "    \"X-Subscription-Token\": API_KEY\n",
    "}\n",
    "\n",
    "# ─── 1) SEND ONE REQUEST ─────────────────────────────────────────────────────────\n",
    "params = {\n",
    "    \"q\": QUERY,\n",
    "    # you can also specify `count` (max 20 for web) and `offset` here if you want pagination:\n",
    "    # \"count\": 20,\n",
    "    # \"offset\": 0,\n",
    "    # \"result_filter\": \"web,videos\"\n",
    "}\n",
    "\n",
    "response = requests.get(BASE_URL, headers=HEADERS, params=params)\n",
    "response.raise_for_status()\n",
    "result = response.json()\n",
    "\n",
    "\n",
    "# ─── 2) EXTRACT \"videos\" RESULTS ────────────────────────────────────────────────\n",
    "video_rows = []\n",
    "if \"videos\" in result and isinstance(result[\"videos\"].get(\"results\", []), list):\n",
    "    for entry in result[\"videos\"][\"results\"]:\n",
    "        # Start with a base dict containing all the video fields… \n",
    "        row = {\n",
    "            \"type\": \"video\", \n",
    "            # you can pick whichever fields you care about; these are examples:\n",
    "            \"title\": entry.get(\"title\"),\n",
    "            \"url\": entry.get(\"url\"),\n",
    "            \"description\": entry.get(\"description\"),\n",
    "            \"thumbnail\": entry.get(\"thumbnail\"),\n",
    "            # if you want more fields in the CSV, just add them here:\n",
    "            # e.g. entry.get(\"video\", {}).get(\"duration\"), etc.\n",
    "        }\n",
    "        video_rows.append(row)\n",
    "\n",
    "\n",
    "# ─── 3) EXTRACT \"web\" RESULTS ───────────────────────────────────────────────────\n",
    "web_rows = []\n",
    "if \"web\" in result and isinstance(result[\"web\"].get(\"results\", []), list):\n",
    "    for entry in result[\"web\"][\"results\"]:\n",
    "        row = {\n",
    "            \"type\": \"web\",\n",
    "            \"title\": entry.get(\"title\"),\n",
    "            \"url\": entry.get(\"url\"),\n",
    "            \"description\": entry.get(\"description\"),\n",
    "            # you can pull in any of the other keys, for example:\n",
    "            \"language\": entry.get(\"language\"),\n",
    "            \"page_age\": entry.get(\"page_age\"),\n",
    "        }\n",
    "        web_rows.append(row)\n",
    "\n",
    "\n",
    "# ─── 4) COMBINE + SAVE TO CSV ───────────────────────────────────────────────────\n",
    "all_rows = video_rows + web_rows\n",
    "df = pd.DataFrame(all_rows)\n",
    "\n",
    "# Re-order columns so \"type\" is first:\n",
    "cols = [\"type\"] + [c for c in df.columns if c != \"type\"]\n",
    "df = df[cols]\n",
    "\n",
    "df.to_csv(OUTPUT_CSV, index=False)\n",
    "print(f\"Saved {len(df)} rows to {OUTPUT_CSV!r}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "200dd7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# ─── CONFIG ─────────────────────────────────────────────────────────────────────\n",
    "API_KEY = os.getenv(\"BRAVE_SEARCH_API_KEY\")\n",
    "if not API_KEY:\n",
    "    raise ValueError(\"Please set BRAVE_SEARCH_API_KEY as an environment variable.\")\n",
    "\n",
    "QUERY = \"Predicting Customer Lifetime Value\"\n",
    "RESULTS_PER_PAGE = 50     # max allowed by this endpoint\n",
    "TOTAL_RESULTS = 1000      # total desired results\n",
    "OUTPUT_CSV = \"clv_search_results.csv\"\n",
    "\n",
    "BASE_URL = \"https://api.search.brave.com/res/v1/web/search\"\n",
    "HEADERS = {\n",
    "    \"Accept\": \"application/json\",\n",
    "    \"Accept-Encoding\": \"gzip\",\n",
    "    \"X-Subscription-Token\": API_KEY\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498d4d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "        \"q\": QUERY\n",
    "    }\n",
    "\n",
    "response = requests.get(BASE_URL, headers=HEADERS, params=params)\n",
    "response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1b04b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8abc479c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['query', 'mixed', 'type', 'videos', 'web']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(result.keys())\n",
    "# ['query', 'mixed', 'type', 'videos', 'web']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e5dc8d87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['type', 'url', 'title', 'description', 'video', 'meta_url', 'thumbnail']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(result['videos']['results'][0].keys())\n",
    "# ['type', 'url', 'title', 'description', 'video', 'meta_url', 'thumbnail']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "93c615c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['title',\n",
       " 'url',\n",
       " 'is_source_local',\n",
       " 'is_source_both',\n",
       " 'description',\n",
       " 'page_age',\n",
       " 'profile',\n",
       " 'language',\n",
       " 'family_friendly',\n",
       " 'type',\n",
       " 'subtype',\n",
       " 'is_live',\n",
       " 'meta_url',\n",
       " 'thumbnail',\n",
       " 'age',\n",
       " 'extra_snippets']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(result[\"web\"][\"results\"][0].keys())\n",
    "\n",
    "# ['title',\n",
    "#  'url',\n",
    "#  'is_source_local',\n",
    "#  'is_source_both',\n",
    "#  'description',\n",
    "#  'page_age',\n",
    "#  'profile',\n",
    "#  'language',\n",
    "#  'family_friendly',\n",
    "#  'type',\n",
    "#  'subtype',\n",
    "#  'is_live',\n",
    "#  'meta_url',\n",
    "#  'thumbnail',\n",
    "#  'age',\n",
    "#  'extra_snippets']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9a9a191a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 25 rows to 'clv_search_results.csv'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ─── 2) EXTRACT \"videos\" RESULTS ────────────────────────────────────────────────\n",
    "video_rows = []\n",
    "if \"videos\" in result and isinstance(result[\"videos\"].get(\"results\", []), list):\n",
    "    for entry in result[\"videos\"][\"results\"]:\n",
    "        # Start with a base dict containing all the video fields… \n",
    "        row = {\n",
    "            \"type\": \"video\", \n",
    "            # you can pick whichever fields you care about; these are examples:\n",
    "            \"title\": entry.get(\"title\"),\n",
    "            \"url\": entry.get(\"url\"),\n",
    "            \"description\": entry.get(\"description\"),\n",
    "            \"thumbnail\": entry.get(\"thumbnail\"),\n",
    "            # if you want more fields in the CSV, just add them here:\n",
    "            # e.g. entry.get(\"video\", {}).get(\"duration\"), etc.\n",
    "        }\n",
    "        video_rows.append(row)\n",
    "\n",
    "\n",
    "# ─── 3) EXTRACT \"web\" RESULTS ───────────────────────────────────────────────────\n",
    "web_rows = []\n",
    "if \"web\" in result and isinstance(result[\"web\"].get(\"results\", []), list):\n",
    "    for entry in result[\"web\"][\"results\"]:\n",
    "        row = {\n",
    "            \"type\": \"web\",\n",
    "            \"title\": entry.get(\"title\"),\n",
    "            \"url\": entry.get(\"url\"),\n",
    "            \"description\": entry.get(\"description\"),\n",
    "            # you can pull in any of the other keys, for example:\n",
    "            \"language\": entry.get(\"language\"),\n",
    "            \"page_age\": entry.get(\"page_age\"),\n",
    "        }\n",
    "        web_rows.append(row)\n",
    "\n",
    "\n",
    "# ─── 4) COMBINE + SAVE TO CSV ───────────────────────────────────────────────────\n",
    "all_rows = video_rows + web_rows\n",
    "df = pd.DataFrame(all_rows)\n",
    "\n",
    "# Re-order columns so \"type\" is first:\n",
    "cols = [\"type\"] + [c for c in df.columns if c != \"type\"]\n",
    "df = df[cols]\n",
    "\n",
    "df.to_csv(OUTPUT_CSV, index=False)\n",
    "print(f\"Saved {len(df)} rows to {OUTPUT_CSV!r}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4b9b77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbae3cd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec9138e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05351987",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ─── FETCH RESULTS ──────────────────────────────────────────────────────────────\n",
    "all_hits = []\n",
    "offset = 0\n",
    "\n",
    "while offset < TOTAL_RESULTS:\n",
    "    params = {\n",
    "        \"q\": QUERY,\n",
    "        \"count\": RESULTS_PER_PAGE,\n",
    "        \"offset\": offset\n",
    "    }\n",
    "\n",
    "    response = requests.get(BASE_URL, headers=HEADERS, params=params)\n",
    "    if response.status_code != 200:\n",
    "        raise RuntimeError(f\"Brave API error {response.status_code}: {response.text}\")\n",
    "\n",
    "    data = response.json()\n",
    "    results = data.get(\"web\", {}).get(\"results\", [])\n",
    "\n",
    "    if not results:\n",
    "        print(f\"No more results at offset {offset}; stopping.\")\n",
    "        break\n",
    "\n",
    "    for res in results:\n",
    "        all_hits.append({\n",
    "            \"title\": res.get(\"title\"),\n",
    "            \"url\": res.get(\"url\"),\n",
    "            \"description\": res.get(\"description\"),\n",
    "            \"source\": res.get(\"source\"),\n",
    "            \"published\": res.get(\"published\"),\n",
    "            \"type\": res.get(\"type\")\n",
    "        })\n",
    "\n",
    "    offset += RESULTS_PER_PAGE\n",
    "    time.sleep(1.0)  # Respect Brave API rate limits (1 req/sec on free plan)\n",
    "\n",
    "print(f\"Fetched {len(all_hits)} results total.\")\n",
    "\n",
    "# ─── SAVE TO CSV ────────────────────────────────────────────────────────────────\n",
    "df = pd.DataFrame(all_hits)\n",
    "df.to_csv(OUTPUT_CSV, index=False)\n",
    "print(f\"Saved to {OUTPUT_CSV}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
